{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "from os import path\n",
    "from itertools import chain, combinations\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_vector(word_, model):\n",
    "    if len(word_.split(' ')) == 1:\n",
    "        if add_pos_tag:\n",
    "            word = add_pos_tag_to_word(word_)\n",
    "        else:\n",
    "            word = word_\n",
    "        try:\n",
    "            return model[word]\n",
    "        except KeyError:\n",
    "            return np.zeros(shape=model.vector_size)\n",
    "    else:\n",
    "        vector = np.zeros(shape=model.vector_size)\n",
    "        for subword in word_.split(' '):\n",
    "            if add_pos_tag:\n",
    "                word = add_pos_tag_to_word(subword)\n",
    "            else:\n",
    "                word = subword\n",
    "            try:\n",
    "                vector = np.add(vector, model[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        return vector / len(word_.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_pos_tag_to_word(word):\n",
    "    return '{}_{}'.format(word, m.parse(word)[0].tag.POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = load(open(path.join('..', 'data', 'test.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language = 'russian'\n",
    "architecture = 'Word2Vec'\n",
    "path_to_models = path.join('..', '..', '..', 'monolang', 'MODELS', architecture, language)\n",
    "models_names = ['ruwikiruscorpora-superbigrams_skipgram_300_2_2018.vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for model_name in models_names:\n",
    "    models[model_name] = KeyedVectors.load_word2vec_format(path.join(path_to_models, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "microframes_dict = {}\n",
    "for word, anket in words.items():\n",
    "    microframes_dict[word] = list(chain.from_iterable(anket.values()))\n",
    "word_pairs = list(combinations(microframes_dict.keys(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation typology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectors_distance(word1, word2, model, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return 1 - cosine(model[word1], model[word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_distance(wordlist1, wordlist2):\n",
    "    wordset1 = set(wordlist1)\n",
    "    wordset2 = set(wordlist2)\n",
    "    return float(len(wordset1 & wordset2)) / len(wordset1 | wordset2)\n",
    "\n",
    "def sorensen_dice_distance(wordlist1, wordlist2):\n",
    "    intersection = np.logical_and(wordlist1, wordlist2)\n",
    "    return 2. * intersection.sum() / (wordlist1.sum() + wordlist2.sum())\n",
    "\n",
    "def get_wordlist_similarity(wordlist1, wordlist2, metric='jaccard'):\n",
    "    if metric == 'jaccard':\n",
    "        return jaccard_distance(wordlist1, wordlist2)\n",
    "    elif metric == 'sorensen':\n",
    "        return sorensen_dice_distance(wordlist1, wordlist2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
