{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from itertools import chain, combinations\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pandas import DataFrame, read_csv\n",
    "from collections import defaultdict\n",
    "from russian_tagsets import converters\n",
    "from re import sub\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "m = MorphAnalyzer()\n",
    "conv = converters.converter('opencorpora-int', 'ud14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(word_, model, add_pos_tag=True):\n",
    "    if len(word_.split(' ')) == 1:\n",
    "        if add_pos_tag:\n",
    "            word = add_pos_tag_to_word(word_)\n",
    "        else:\n",
    "            word = word_\n",
    "        try:\n",
    "            return model[word]\n",
    "        except KeyError:\n",
    "            return np.zeros(shape=model.vector_size)\n",
    "    else:\n",
    "        vector = np.zeros(shape=model.vector_size)\n",
    "        for subword in word_.split(' '):\n",
    "            if add_pos_tag:\n",
    "                word = add_pos_tag_to_word(subword)\n",
    "            else:\n",
    "                word = subword\n",
    "            try:\n",
    "                vector = np.add(vector, model[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        return vector / len(word_.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pos_tag_to_word(word_):\n",
    "    word = sub(r'\\W+', '', word_)\n",
    "    return '{}_{}'.format(word, conv(m.parse(word)[0].tag.POS).split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'russian'\n",
    "architecture = 'Word2Vec'\n",
    "path_to_models = path.join('..', '..', '..', 'monolang', 'MODELS', architecture, language)\n",
    "models_names = ['ruwikiruscorpora-superbigrams_skipgram_300_2_2018.vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for model_name in models_names:\n",
    "    models[model_name] = KeyedVectors.load_word2vec_format(path.join(path_to_models, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_lists_for_lexical_field(field_name='size_adj.csv', column_from_which_words_start = 3):\n",
    "    df = read_csv(path.join('..', 'data', field_name)).fillna(0)\n",
    "    words = defaultdict(lambda: [])\n",
    "    for _, row in df.iterrows():\n",
    "        for column_name in df.columns[column_from_which_words_start:]:\n",
    "            if row[column_name]:\n",
    "                words[column_name].append(row['microframe'])\n",
    "    return dict(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on typology 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_distance(word1, word2, model, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return 1 - cosine(get_word_vector(word1, model), get_word_vector(word2, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(wordlist1, wordlist2):\n",
    "    wordset1 = set(wordlist1)\n",
    "    wordset2 = set(wordlist2)\n",
    "    return float(len(wordset1 & wordset2)) / len(wordset1 | wordset2)\n",
    "\n",
    "def sorensen_dice_distance(wordlist1, wordlist2):\n",
    "    intersection = np.logical_and(wordlist1, wordlist2)\n",
    "    return 2. * intersection.sum() / (wordlist1.sum() + wordlist2.sum())\n",
    "\n",
    "def get_wordlist_distance(wordlist1, wordlist2, metric='jaccard'):\n",
    "    if metric == 'jaccard':\n",
    "        return jaccard_distance(wordlist1, wordlist2)\n",
    "    elif metric == 'sorensen':\n",
    "        return sorensen_dice_distance(wordlist1, wordlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_typology_1(model):\n",
    "    results = []\n",
    "    words = get_word_lists_for_lexical_field()\n",
    "    word_pairs = list(combinations(words.keys(), 2))\n",
    "    for word_pair in word_pairs:\n",
    "        vector_distance = get_vectors_distance(word_pair[0], word_pair[1], model)\n",
    "        wordlist_distance = get_wordlist_distance(words[word_pair[0]], words[word_pair[1]])\n",
    "        results.append({'pair' : word_pair, 'vector' : vector_distance, 'wordlist' : wordlist_distance})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = DataFrame(evaluate_on_typology_1(models['ruwikiruscorpora-s.vec']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.29283678863284196, pvalue=0.009273244509341683)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(q.vector, q.wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
